{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71803d9a",
   "metadata": {},
   "source": [
    "# 1. Building Custom Environment (NSL-KDD Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9990c851",
   "metadata": {},
   "source": [
    "This section involves using OpenAI Gym to develop our Deep Reinforcement Learning (DRL) environment. The environment that we define will have the following characteristics and act as a multi-class classifier:\n",
    "\n",
    "Actions:\n",
    "\n",
    "0 (do not alert)\n",
    "<br>\n",
    "1 (DoS alert)\n",
    "<br>\n",
    "2 (Probe)\n",
    "<br>\n",
    "3 (R2L)\n",
    "<br>\n",
    "4 (U2R)\n",
    "\n",
    "Rewards:\n",
    "\n",
    "+1 if agent correctly alerts to the correct type of attack <br>\n",
    "0 if agent does not raise an alert when it is not needed <br>\n",
    "-1 if agent does not raise an alert when there is an attack <br>\n",
    "-1 if agent raises alert when there is not one needed <br>\n",
    "-1 if agent raises an alert to the incorrect type of attack <br>\n",
    "\n",
    "Episode Termination Condition:\n",
    "\n",
    "i. An episode reaches >= 500 steps <br>\n",
    "ii. An attack is issued and no alert is made <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fa00830f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycm==3.3\n",
      "  Downloading pycm-3.3-py2.py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 464 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /home/caro/anaconda3/envs/NetSecurity-ML/lib/python3.7/site-packages (from pycm==3.3) (1.21.4)\n",
      "Collecting art>=1.8\n",
      "  Downloading art-5.3-py2.py3-none-any.whl (574 kB)\n",
      "\u001b[K     |████████████████████████████████| 574 kB 5.1 MB/s eta 0:00:0101\n",
      "\u001b[?25hInstalling collected packages: art, pycm\n",
      "Successfully installed art-5.3 pycm-3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install pycm==3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2e349b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and filtering unnecessary tensorflow warnings\n",
    "\n",
    "import gym \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycm import *\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.common.policies import FeedForwardPolicy\n",
    "from stable_baselines.common.callbacks import BaseCallback\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import swifter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8c67a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_NSL-KDD.csv\")\n",
    "df=df.rename(columns = {'Class':'label'})\n",
    "\n",
    "\n",
    "# converting any label != 0 to 1, so we just determine attack or not\n",
    "# df.label = df.label.astype(bool).astype(int)\n",
    "\n",
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        if (feature_name == 'label'):\n",
    "            continue\n",
    "        else:\n",
    "            max_value = df[feature_name].max()\n",
    "            min_value = df[feature_name].min()\n",
    "            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "\n",
    "df = normalize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7dda2db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train percentage:  72.24702848877429 %\n",
      "test percentage:  15.001152967318617 %\n",
      "validation percentage  12.751818543907092 %\n",
      "[4 1 0 2 3]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(             # using 15% of the data for testing\n",
    "    df.iloc[:, :-1], df[\"label\"], test_size=0.15, shuffle=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(               # using 15% of the data for validation\n",
    "    X_train, y_train, test_size=0.15, shuffle=True)\n",
    "\n",
    "print(\"train percentage: \", len(X_train)/len(df.index) * 100, \"%\")\n",
    "print(\"test percentage: \", len(X_test)/len(df.index) * 100, \"%\")\n",
    "print(\"validation percentage \", len(X_val)/len(df.index) * 100, \"%\")\n",
    "\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "val_data = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "print(train_data.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "649c215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # or any {'0', '1', '2'}\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=Warning)\n",
    "\n",
    "tf.get_logger().setLevel(\"INFO\")\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "969344e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRL_IDS_Env(gym.Env):\n",
    "    def __init__(self, train_data): # test data created in last module\n",
    "        '''\n",
    "        constructor\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.train_data = train_data\n",
    "    \n",
    "        # set limit for episode to 500 steps\n",
    "        self.max_steps = 500\n",
    "        self.extra_steps = None # counter for steps going beyond the max_steps limit\n",
    "    \n",
    "        # defining the reward function as discussed above\n",
    "        # [(true_label, action) : reward]\n",
    "        \n",
    "        '''\n",
    "        self.rewards = {(0, 1): -1, # (benign, alert) : -1\n",
    "                        (1, 0): -1, # (attack, no alert) : -1\n",
    "                        (1, 1): 1, # (attack, alert) : 1\n",
    "                        (0, 0): 0, # (benign, no alert) : 0\n",
    "        '''\n",
    "        \n",
    "        self.rewards = {(0, 0): 0,\n",
    "                        (0, 1): -1,\n",
    "                        (0, 2): -1,\n",
    "                        (0, 3): -1,\n",
    "                        (0, 4): -1,\n",
    "                        (1, 0): -1,\n",
    "                        (1, 1): 1, \n",
    "                        (1, 2): -1,\n",
    "                        (1, 3): -1,\n",
    "                        (1, 4): -1,\n",
    "                        (2, 0): -1,\n",
    "                        (2, 1): -1,\n",
    "                        (2, 2): 1,\n",
    "                        (2, 3): -1,\n",
    "                        (2, 4): -1,\n",
    "                        (3, 0): -1,\n",
    "                        (3, 1): -1,\n",
    "                        (3, 2): -1,\n",
    "                        (3, 3): 1,\n",
    "                        (3, 4): -1,\n",
    "                        (4, 0): -1,\n",
    "                        (4, 1): -1,\n",
    "                        (4, 2): -1,\n",
    "                        (4, 3): -1,\n",
    "                        (4, 4): 1}\n",
    "        \n",
    "        # defining action/observation space\n",
    "        self.action_space = gym.spaces.Discrete(5)  # either 0 (NORMAL) or 1 (ATTACK)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(train_data.shape[1] - 1,), dtype=np.float64) # 'box' implies we are dealing with real, valued quantities\n",
    "    \n",
    "    def step(self, action):\n",
    "        '''\n",
    "        agent taking a single step\n",
    "        this method is called after an agent takes a step\n",
    "        '''\n",
    "        \n",
    "        # check if action exists in action space\n",
    "        try:\n",
    "            self.action_space.contains(action)\n",
    "        except AssertionError as msg:\n",
    "            print(msg)\n",
    "        \n",
    "        # determine if the episode is finished\n",
    "        ep_info = {}\n",
    "        finished = False\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= self.max_steps:\n",
    "            ep_info['end_cause'] = 'max_step_limit_reached'\n",
    "            finished = True # we do not want to exceed our max step limit\n",
    "        \n",
    "        if self.label == 1 and action == 0: # this implies there was an attack that we did not alert\n",
    "            ep_info['end_cause'] = 'attack_unalerted'\n",
    "            finished = True\n",
    "            \n",
    "        # calculate reward based on the label of the observation and action taken by agent\n",
    "        reward = self.rewards[(self.label, action)] # maps back to our self.reward dictionary\n",
    "        \n",
    "        # calculate the next state if finished = False\n",
    "        if not finished:\n",
    "            self.i += 1 # hop to next row in dataset\n",
    "            if self.i >= self.train_data.shape[0]: # if this extends beyond the number of rows in our dataset\n",
    "                self.i = 0 # set back to first 'state'\n",
    "            \n",
    "            self.obs = self.train_data.iloc[self.i] # pulling that row, or 'observation' from our dataset\n",
    "            self.label = int(self.obs.pop('label'))\n",
    "            \n",
    "        elif self.extra_steps is None:\n",
    "            self.extra_steps = 0\n",
    "        else:\n",
    "            if self.extra_steps == 0:\n",
    "                gym.logger.warn('Episode max_step length exceeded. You are entering uncharted territory and should reset the episode.')\n",
    "                self.extra_steps += 1\n",
    "                reward = 0\n",
    "                \n",
    "        return self.obs.values, reward, finished, ep_info\n",
    "    \n",
    "    def reset(self):\n",
    "        \n",
    "        extra_steps = None\n",
    "        self.current_step = 0\n",
    "        \n",
    "        self.i = np.random.randint(0, self.train_data.shape[0]) # pick a random starting location from the 0th row to the nth row\n",
    "\n",
    "        self.obs = self.train_data.iloc[self.i]\n",
    "        # record the true label of self.obs\n",
    "        self.label = int(self.obs.pop('label'))\n",
    "        \n",
    "        return self.obs.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73609ea8",
   "metadata": {},
   "source": [
    "Now we will create an instance of DRL_IDS_Env (and validate it using stable_baselines)\n",
    "Note: stable_baselines (https://stable-baselines.readthedocs.io/en/master/) is a set of improved implementations of Reinforcement Learning (RL) algorithms based on OpenAI Baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3d2cd001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv(\"processed_data/train.csv\")\n",
    "env = DRL_IDS_Env(train_data)\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c85a10",
   "metadata": {},
   "source": [
    "# 2. Training within Custom Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b768bf7e",
   "metadata": {},
   "source": [
    "We will be training the algorithm on multiple environment in parallel through the stable-baselines lib (vectorized environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bc0c2262",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_envs = 16  # hyperparameter\n",
    "env = DummyVecEnv([lambda: DRL_IDS_Env(train_data)] * n_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ecfbd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining network architecture\n",
    "\n",
    "# https://stable-baselines.readthedocs.io/en/master/guide/custom_policy.html#custom-policy\n",
    "class CustomPolicy(FeedForwardPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomPolicy, self).__init__(\n",
    "            *args,\n",
    "            **kwargs,\n",
    "            net_arch=[128, 64, 32],\n",
    "            act_fun=tf.nn.relu,  # Using the ReLU (REctified Linear Unit) activation function\n",
    "            feature_extraction= \"mlp\" # Multi-Layer Perceptrons\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "690635aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ADJUST THESE HYPERPARAMETERS\n",
    "\n",
    "'''\n",
    "The Proximal Policy Optimization algorithm combines ideas from A2C (having multiple workers) and TRPO\n",
    "(it uses a trust region to improve the actor).\n",
    "\n",
    "The main idea is that after an update, the new policy should be not too far from the old policy. For that, PPO\n",
    "uses clipping to avoid too large of updates.\n",
    "'''\n",
    "model = PPO2(\n",
    "    CustomPolicy,\n",
    "    env,\n",
    "    gamma=0.9,\n",
    "    n_steps=512,\n",
    "    ent_coef=1e-05,\n",
    "    learning_rate=lambda progress: progress\n",
    "    * 0.0021,  # progress decreases from 1 to 0 -> lr decreasesb from 0.0021 to 0\n",
    "    vf_coef=0.6,\n",
    "    max_grad_norm=0.8,\n",
    "    lam=0.8,\n",
    "    nminibatches=16,\n",
    "    noptepochs=55,\n",
    "    cliprange=0.2,\n",
    "    verbose=0,\n",
    "    tensorboard_log=\"log_25\",  # define the tensorboard log location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b66c5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccF1Callback(BaseCallback):\n",
    "    def __init__(self, train, val, eval_freq):\n",
    "        super().__init__()\n",
    "        self.train_data = train\n",
    "        self.val_data = val\n",
    "        self.eval_freq = eval_freq\n",
    "\n",
    "    def _on_step(self):\n",
    "        '''\n",
    "        _on_step will be called after every eval_freq steps\n",
    "        '''\n",
    "\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            super()._on_step()\n",
    "\n",
    "            predicted = self.train_data.drop(columns=[\"label\"]).swifter.apply(lambda x: self.model.predict(x, deterministic=True)[0], axis=1)\n",
    "            cm = ConfusionMatrix(self.train_data[\"label\"].tolist(), predicted, digit=5)\n",
    "            print(\"*-\" * 50)\n",
    "            \n",
    "            print(\"total current timesteps: \", self.num_timesteps, '\\n')\n",
    "            # The accuracy is the number of correct predictions from all predictions made\n",
    "            print('Overall Training Accuracy: ', cm.Overall_ACC)\n",
    "            # In statistical analysis of classification, the F1 score (also F-score or F-measure) is a measure of a test's accuracy. It considers both the precision p\n",
    "            # and the recall r of the test to compute the score. The F1 score is the harmonic average of the precision and recall, where F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0\n",
    "            print(\"Training F1 Scores: \", cm.F1)\n",
    "            \n",
    "            print('\\n')\n",
    "            predicted = self.val_data.drop(columns=[\"label\"]).swifter.apply(lambda x: self.model.predict(x, deterministic=True)[0], axis=1)\n",
    "            cm = ConfusionMatrix(self.val_data[\"label\"].tolist(), predicted, digit=5)\n",
    "            # The accuracy is the number of correct predictions from all predictions made\n",
    "            print('Overall Validation Accuracy: ', cm.Overall_ACC)\n",
    "            # In statistical analysis of classification, the F1 score (also F-score or F-measure) is a measure of a test's accuracy. It considers both the precision p\n",
    "            # and the recall r of the test to compute the score. The F1 score is the harmonic average of the precision and recall, where F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0\n",
    "            print(\"Validation F1 Scores: \", cm.F1)\n",
    "            \n",
    "            print(\"*-\" * 50)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5f0be04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data = pd.read_csv(\"processed_data/val.csv\")\n",
    "eval_callback = AccF1Callback(train_data, val_data, eval_freq=1000 // n_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0bfe3c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  992 \n",
      "\n",
      "Overall Training Accuracy:  0.99544452181987\n",
      "Training F1 Scores:  {0: 0.9978836952521163, 1: 0.9958872265601717, 2: 0.9623029472241261, 3: 0.4793388429752066, 4: 0.9971909138200103}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9947394377774125\n",
      "Validation F1 Scores:  {0: 0.9973656480505796, 1: 0.9945982444294396, 2: 0.9608540925266904, 3: 0.26666666666666666, 4: 0.9968701095461658}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  1984 \n",
      "\n",
      "Overall Training Accuracy:  0.99544452181987\n",
      "Training F1 Scores:  {0: 0.9978836952521163, 1: 0.9958872265601717, 2: 0.9623029472241261, 3: 0.4793388429752066, 4: 0.9971909138200103}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9947394377774125\n",
      "Validation F1 Scores:  {0: 0.9973656480505796, 1: 0.9945982444294396, 2: 0.9608540925266904, 3: 0.26666666666666666, 4: 0.9968701095461658}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  2976 \n",
      "\n",
      "Overall Training Accuracy:  0.99544452181987\n",
      "Training F1 Scores:  {0: 0.9978836952521163, 1: 0.9958872265601717, 2: 0.9623029472241261, 3: 0.4793388429752066, 4: 0.9971909138200103}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9947394377774125\n",
      "Validation F1 Scores:  {0: 0.9973656480505796, 1: 0.9945982444294396, 2: 0.9608540925266904, 3: 0.26666666666666666, 4: 0.9968701095461658}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  3968 \n",
      "\n",
      "Overall Training Accuracy:  0.99544452181987\n",
      "Training F1 Scores:  {0: 0.9978836952521163, 1: 0.9958872265601717, 2: 0.9623029472241261, 3: 0.4793388429752066, 4: 0.9971909138200103}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9947394377774125\n",
      "Validation F1 Scores:  {0: 0.9973656480505796, 1: 0.9945982444294396, 2: 0.9608540925266904, 3: 0.26666666666666666, 4: 0.9968701095461658}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  4960 \n",
      "\n",
      "Overall Training Accuracy:  0.99544452181987\n",
      "Training F1 Scores:  {0: 0.9978836952521163, 1: 0.9958872265601717, 2: 0.9623029472241261, 3: 0.4793388429752066, 4: 0.9971909138200103}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9947394377774125\n",
      "Validation F1 Scores:  {0: 0.9973656480505796, 1: 0.9945982444294396, 2: 0.9608540925266904, 3: 0.26666666666666666, 4: 0.9968701095461658}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  5952 \n",
      "\n",
      "Overall Training Accuracy:  0.99544452181987\n",
      "Training F1 Scores:  {0: 0.9978836952521163, 1: 0.9958872265601717, 2: 0.9623029472241261, 3: 0.4793388429752066, 4: 0.9971909138200103}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9947394377774125\n",
      "Validation F1 Scores:  {0: 0.9973656480505796, 1: 0.9945982444294396, 2: 0.9608540925266904, 3: 0.26666666666666666, 4: 0.9968701095461658}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  6944 \n",
      "\n",
      "Overall Training Accuracy:  0.99544452181987\n",
      "Training F1 Scores:  {0: 0.9978836952521163, 1: 0.9958872265601717, 2: 0.9623029472241261, 3: 0.4793388429752066, 4: 0.9971909138200103}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9947394377774125\n",
      "Validation F1 Scores:  {0: 0.9973656480505796, 1: 0.9945982444294396, 2: 0.9608540925266904, 3: 0.26666666666666666, 4: 0.9968701095461658}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  7936 \n",
      "\n",
      "Overall Training Accuracy:  0.99544452181987\n",
      "Training F1 Scores:  {0: 0.9978836952521163, 1: 0.9958872265601717, 2: 0.9623029472241261, 3: 0.4793388429752066, 4: 0.9971909138200103}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9947394377774125\n",
      "Validation F1 Scores:  {0: 0.9973656480505796, 1: 0.9945982444294396, 2: 0.9608540925266904, 3: 0.26666666666666666, 4: 0.9968701095461658}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  8928 \n",
      "\n",
      "Overall Training Accuracy:  0.9959377901578459\n",
      "Training F1 Scores:  {0: 0.9991720331186753, 1: 0.9954713383386963, 2: 0.963276836158192, 3: 0.5607476635514018, 4: 0.9969878475227643}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9939174749301332\n",
      "Validation F1 Scores:  {0: 0.9973642593568793, 1: 0.9922375970300371, 2: 0.9477611940298507, 3: 0.3076923076923077, 4: 0.9964898595943837}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  9920 \n",
      "\n",
      "Overall Training Accuracy:  0.9959377901578459\n",
      "Training F1 Scores:  {0: 0.9991720331186753, 1: 0.9954713383386963, 2: 0.963276836158192, 3: 0.5607476635514018, 4: 0.9969878475227643}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9939174749301332\n",
      "Validation F1 Scores:  {0: 0.9973642593568793, 1: 0.9922375970300371, 2: 0.9477611940298507, 3: 0.3076923076923077, 4: 0.9964898595943837}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  10912 \n",
      "\n",
      "Overall Training Accuracy:  0.9959377901578459\n",
      "Training F1 Scores:  {0: 0.9991720331186753, 1: 0.9954713383386963, 2: 0.963276836158192, 3: 0.5607476635514018, 4: 0.9969878475227643}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9939174749301332\n",
      "Validation F1 Scores:  {0: 0.9973642593568793, 1: 0.9922375970300371, 2: 0.9477611940298507, 3: 0.3076923076923077, 4: 0.9964898595943837}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  11904 \n",
      "\n",
      "Overall Training Accuracy:  0.9959377901578459\n",
      "Training F1 Scores:  {0: 0.9991720331186753, 1: 0.9954713383386963, 2: 0.963276836158192, 3: 0.5607476635514018, 4: 0.9969878475227643}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9939174749301332\n",
      "Validation F1 Scores:  {0: 0.9973642593568793, 1: 0.9922375970300371, 2: 0.9477611940298507, 3: 0.3076923076923077, 4: 0.9964898595943837}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  12896 \n",
      "\n",
      "Overall Training Accuracy:  0.9959377901578459\n",
      "Training F1 Scores:  {0: 0.9991720331186753, 1: 0.9954713383386963, 2: 0.963276836158192, 3: 0.5607476635514018, 4: 0.9969878475227643}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9939174749301332\n",
      "Validation F1 Scores:  {0: 0.9973642593568793, 1: 0.9922375970300371, 2: 0.9477611940298507, 3: 0.3076923076923077, 4: 0.9964898595943837}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  13888 \n",
      "\n",
      "Overall Training Accuracy:  0.9959377901578459\n",
      "Training F1 Scores:  {0: 0.9991720331186753, 1: 0.9954713383386963, 2: 0.963276836158192, 3: 0.5607476635514018, 4: 0.9969878475227643}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9939174749301332\n",
      "Validation F1 Scores:  {0: 0.9973642593568793, 1: 0.9922375970300371, 2: 0.9477611940298507, 3: 0.3076923076923077, 4: 0.9964898595943837}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  14880 \n",
      "\n",
      "Overall Training Accuracy:  0.9959377901578459\n",
      "Training F1 Scores:  {0: 0.9991720331186753, 1: 0.9954713383386963, 2: 0.963276836158192, 3: 0.5607476635514018, 4: 0.9969878475227643}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9939174749301332\n",
      "Validation F1 Scores:  {0: 0.9973642593568793, 1: 0.9922375970300371, 2: 0.9477611940298507, 3: 0.3076923076923077, 4: 0.9964898595943837}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  15872 \n",
      "\n",
      "Overall Training Accuracy:  0.9959377901578459\n",
      "Training F1 Scores:  {0: 0.9991720331186753, 1: 0.9954713383386963, 2: 0.963276836158192, 3: 0.5607476635514018, 4: 0.9969878475227643}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9939174749301332\n",
      "Validation F1 Scores:  {0: 0.9973642593568793, 1: 0.9922375970300371, 2: 0.9477611940298507, 3: 0.3076923076923077, 4: 0.9964898595943837}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  16864 \n",
      "\n",
      "Overall Training Accuracy:  0.9960828690807799\n",
      "Training F1 Scores:  {0: 0.9977428716200654, 1: 0.9951219512195122, 2: 0.9771941948859709, 3: 0.594059405940594, 4: 0.9977478257856623}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9950682229163241\n",
      "Validation F1 Scores:  {0: 0.9973628691983122, 1: 0.9919082939986514, 2: 0.9782608695652174, 3: 0.3076923076923077, 4: 0.9978511428013284}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  17856 \n",
      "\n",
      "Overall Training Accuracy:  0.9960828690807799\n",
      "Training F1 Scores:  {0: 0.9977428716200654, 1: 0.9951219512195122, 2: 0.9771941948859709, 3: 0.594059405940594, 4: 0.9977478257856623}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9950682229163241\n",
      "Validation F1 Scores:  {0: 0.9973628691983122, 1: 0.9919082939986514, 2: 0.9782608695652174, 3: 0.3076923076923077, 4: 0.9978511428013284}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  18848 \n",
      "\n",
      "Overall Training Accuracy:  0.9960828690807799\n",
      "Training F1 Scores:  {0: 0.9977428716200654, 1: 0.9951219512195122, 2: 0.9771941948859709, 3: 0.594059405940594, 4: 0.9977478257856623}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9950682229163241\n",
      "Validation F1 Scores:  {0: 0.9973628691983122, 1: 0.9919082939986514, 2: 0.9782608695652174, 3: 0.3076923076923077, 4: 0.9978511428013284}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  19840 \n",
      "\n",
      "Overall Training Accuracy:  0.9960828690807799\n",
      "Training F1 Scores:  {0: 0.9977428716200654, 1: 0.9951219512195122, 2: 0.9771941948859709, 3: 0.594059405940594, 4: 0.9977478257856623}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9950682229163241\n",
      "Validation F1 Scores:  {0: 0.9973628691983122, 1: 0.9919082939986514, 2: 0.9782608695652174, 3: 0.3076923076923077, 4: 0.9978511428013284}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  20832 \n",
      "\n",
      "Overall Training Accuracy:  0.9960828690807799\n",
      "Training F1 Scores:  {0: 0.9977428716200654, 1: 0.9951219512195122, 2: 0.9771941948859709, 3: 0.594059405940594, 4: 0.9977478257856623}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9950682229163241\n",
      "Validation F1 Scores:  {0: 0.9973628691983122, 1: 0.9919082939986514, 2: 0.9782608695652174, 3: 0.3076923076923077, 4: 0.9978511428013284}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  21824 \n",
      "\n",
      "Overall Training Accuracy:  0.9960828690807799\n",
      "Training F1 Scores:  {0: 0.9977428716200654, 1: 0.9951219512195122, 2: 0.9771941948859709, 3: 0.594059405940594, 4: 0.9977478257856623}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9950682229163241\n",
      "Validation F1 Scores:  {0: 0.9973628691983122, 1: 0.9919082939986514, 2: 0.9782608695652174, 3: 0.3076923076923077, 4: 0.9978511428013284}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  22816 \n",
      "\n",
      "Overall Training Accuracy:  0.9960828690807799\n",
      "Training F1 Scores:  {0: 0.9977428716200654, 1: 0.9951219512195122, 2: 0.9771941948859709, 3: 0.594059405940594, 4: 0.9977478257856623}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9950682229163241\n",
      "Validation F1 Scores:  {0: 0.9973628691983122, 1: 0.9919082939986514, 2: 0.9782608695652174, 3: 0.3076923076923077, 4: 0.9978511428013284}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "total current timesteps:  23808 \n",
      "\n",
      "Overall Training Accuracy:  0.9960828690807799\n",
      "Training F1 Scores:  {0: 0.9977428716200654, 1: 0.9951219512195122, 2: 0.9771941948859709, 3: 0.594059405940594, 4: 0.9977478257856623}\n",
      "\n",
      "\n",
      "Overall Validation Accuracy:  0.9950682229163241\n",
      "Validation F1 Scores:  {0: 0.9973628691983122, 1: 0.9919082939986514, 2: 0.9782608695652174, 3: 0.3076923076923077, 4: 0.9978511428013284}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13283/3810721102.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/NetSecurity-ML/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    358\u001b[0m                             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmbinds\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneglogpacs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                             mb_loss_vals.append(self._train_step(lr_now, cliprange_now, *slices, writer=writer,\n\u001b[0;32m--> 360\u001b[0;31m                                                                  update=timestep, cliprange_vf=cliprange_vf_now))\n\u001b[0m\u001b[1;32m    361\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# recurrent version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                     \u001b[0mupdate_fac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_batch\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnminibatches\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoptepochs\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NetSecurity-ML/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py\u001b[0m in \u001b[0;36m_train_step\u001b[0;34m(self, learning_rate, cliprange, obs, returns, masks, actions, values, neglogpacs, update, writer, states, cliprange_vf)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 summary, policy_loss, value_loss, policy_entropy, approxkl, clipfrac, _ = self.sess.run(\n\u001b[1;32m    293\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvf_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapproxkl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclipfrac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                     td_map)\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mupdate_fac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NetSecurity-ML/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NetSecurity-ML/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NetSecurity-ML/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NetSecurity-ML/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NetSecurity-ML/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NetSecurity-ML/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(5000000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d0584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d0bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
